---
title: "Clustering Methods"
author: "Mary Solomon"
date: "2/4/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(tidyverse)
library(ggplot2)
library(ggthemes)
library(stringr)
library(scales) #for formatting with percentage signs
library(nnet) #for multinomial regression
```


Read data
```{r}
data <- fread("kpopdata.csv")
colnames(data)
```


# Clustering (unsupervised)
```{r}
mode1 <- data %>% 
  dplyr::filter(mode == 1) %>%
  dplyr::select(popularity, duration, acousticness, danceability, energy, 
         instrumentalness, loudness, speechiness, tempo, valence)
mode0 <- data %>% 
  dplyr::filter(mode == 0) %>%
  dplyr::select(popularity, duration, acousticness, danceability, energy, 
         instrumentalness, loudness, speechiness, tempo, valence)
```
The previous section aims to determine what kind of model we can build in order to predict which generation a kpop song is from based on audio/song features alone. However, could there be an alternative way to group the songs in the kpop genre based on audio/song features? Kpop Generations are grouped by the time and evolution of the kpop genre. By excluding time period, cultural trends, catchy visuals, dances, and only focusing on the audio features of the songs, what will the groups be defined by and how will it differ from the characteristics of the kpop generations observed in previous chapters?

Before we can start clustering, we will perform dimension reduction which will reduce allow us to analyze the data on fewer dimensions yet retain as much accountability for the variation as possible.

## Dimension Reduction: PCA ##

PCA is a dimension reduction technique that defines uncorrelated linear combinations that maximize the variance. Or in otherwords, PCA reduces the dimensions by with linear combinations that maximizes the information explained by the data. The assumptions made to perform PCA dimension reduction are as follows:      

* No assumption on the distribution: this is very good because the majority of the predictors have non-normal skewed distributions       

* No indpendence to be assumed for elements in a random vector: aka colinearity can exist between variables (???)     

* Assume independence between observations in the random sample: this is a fair assumption to make. Each song is composed independently from one another, for the most part.   

* most appropriate for continuous data: this could be a potential issue since there are categorical variables such as key, mode, time signature. Because of this, we will be analyzing the dimension reduction separately for those with a minor mode versus those with major mode, treating the two divisions of the category as separate groups. Time signature will be removed from the analysis since 97% of the songs are detected as being in 4/4 time. Key signature will also be removed as the integer values 0-11 represent a classification into a musical key where the distance between each are not equal. 

#### PCA for Major mode (mode = 1)

standardized PCA
```{r}
pca1 <- prcomp(mode1, scale=TRUE)
t(pca1$rotation)
```

For clearer interpretation, we can express the principal components as linear combinations of the standardized value of each variable. The first 6 PCs are expressed below rounded to 3 decimals: 

$$
\hat y_1 = -0.087z_{Popularity} + 0.235z_{Duration} + 0.427z_{Acousticness} - 0.330z_{Danceability} - 0.502z_{Energy} + 0.089z_{Instrumantalness} - 0.421z_{Loudness} - 0.178z_{speechiness} -0.066z_{tempo} - 0.415z_{valence} 
\\
\hat y_2 = -0.321z_{Popularity} - 0.124z_{Duration} + 0.024z_{Acousticness} + 0.521z_{Danceability} - 0.131z_{Energy} + 0.256z_{Instrumantalness} - 0.269z_{Loudness} - 0.196z_{speechiness} - 0.583z_{tempo} + 0.275z_{valence}
\\
\hat y_3 = 0.539z_{Popularity} - 0.570z_{Duration} + 0.221z_{Acousticness} + 0.105z_{Danceability} - 0.211z_{Energy} + 0.095z_{Instrumantalness} - 0.199z_{Loudness} + 0.478z_{speechiness} - 0.056z_{tempo} - 0.012z_{valence}
\\
\hat y_4 = -0.432z_{Popularity} - 0.146z_{Duration} - 0.131z_{Acousticness} - 0.148z_{Danceability} + 0.069z_{Energy} + 0.658z_{Instrumantalness} - 0.204z_{Loudness} + 0.274z_{speechiness} + 0.440z_{tempo} + 0.068z_{valence}
\\
\hat y_5 = 0.387z_{Popularity} - 0.147z_{Duration} - 0.128z_{Acousticness} - 0.180z_{Danceability} + 0.133z_{Energy} + 0.591z_{Instrumantalness}  + 0.287z_{Loudness} - 0.482z_{speechiness} - 0.202z_{tempo} - 0.240z_{valence}
$$

INTERPRETATION OF THE PCs:     

* PC1: this Principal component has the variables of duration, acousticness, instrumentalness and key grouped in the positive direction against the variables of Popularity, danceability, energy, loudness, speechiness, tempo and valence which are contributing in the negative direction. The variables that have negative loading factors seem to be variables that are characteristics which would determine if a song is very upbeat and achieves mainstream appeal of pop music to be an exciting song that you can dance and move to. The factors with the greater loadings are Energy at -0.502, loudness at -0.421, valence at -0.415, and acousticness at 0.427.

* PC2: Here, the positive loading factors are associated with standardized scores for acousticness, danceability, instrumentalness and valence. Where danceability has the greatest positive loading factor at 0.521, therefore accounting for the most variation for the positive loading factors. Whereas the negative direction loading values are coefficients for variables of Popularity, Duration, Energy Loudness, Speechiness, Tempo. For the negative direction standardized variables, Tempo has the largest negative coefficient of -0.583.

* PC3: The positive standardized variables are Popularity, Speechiness, Acousticness, Danceability, and Instrumentalness. Popularity and Speechiness have the highest positive loading factors at 0.539 and 0.478, respectively. For the Negative direction, we have variables of PDuration, Energy, Tempo and Valence, where Duration has the most negative weight at -0.570.     

* PC4: The variable that is weighted with the most variation in this component is instrumentalness with a loading factor of 0.658. Other variables weighted in the positive direction are Tempo, with the second largest loading factor at 0.440, followed by Speechiness, Energy and Valence. In the negative direction, we have popularity, duration, acousticness, danceability, and Loudness, which are more equally weighted than the variables with positive loading factors. The exception however, is popularity which has a substantial negative loading factor of -0.432.

* PC5: The variable with the greatest weight in the positive direction is Instrumentalness with a loading factor of 0.591. The second largest positive factor of 0.387 is for the variable popularity, followed by Loudness and Energy. The variables in the negative direction are Speechiness, Valence, Tempo, Danceability, Duration and Acousticness. In the negative direction, the variable Speechiness holds the most influence with a loading factor of -0.482



biplot
```{r}
biplot(pca1, scale = 0, xlabs=rep("Â·", nrow(mode1)))
```


examine amount of variance explained to choose optimal principal components
```{r}
pca1.var = pca1$sdev^2
pve1 = pca1.var/sum(pca1.var)
cve1 = cumsum(pve1)
pca1.var.explained <- data.frame("Variance" = pca1.var, 
                                "Proportion_Variation" = pve1, 
                                "Cummalitve_Proportion_Variation"= cve1, 
                                "PC" = factor(c("PC1", "PC2", "PC3", "PC4", "PC5", "PC6", "PC7",
                                         "PC8", "PC9", "PC10"), 
                                         levels = c("PC1", "PC2", "PC3", "PC4", "PC5", "PC6", "PC7",
                                         "PC8", "PC9", "PC10")))
pca1.var.explained
```

We can see that by the fifth principal component, 75.5% of the total variation in the data is explained. Therefore, it is reasonable to assume that these 5 principal components are sufficient for capturing the variation and explain the data of kpop songs. Furthermore, we can observe that the first principal component is the most influential by capturing 30% of information from the data. Whereas the remaining principal components explain lesser percentages of the data. This discrepancy in amount of variation explained is also displayed in the Scree plot.

```{r}
pca1.var.explained %>%
  ggplot(aes(x=PC,y=Proportion_Variation, group=1))+
  ylab("Proportion of Variance Explained") +
  geom_point(size=3)+
  geom_line()+
  labs(title="Scree plot: PCA on scaled data") +
  theme_minimal()
```





#### PCA for minor mode (mode = 0)

standardized PCA
```{r}
pca0 <- prcomp(mode0, scale=TRUE)
t(pca0$rotation)
```


$$
\hat y_1 = 0.043z_{Popularity} - 0.138z_{Duration} - 0.440z_{Acousticness} + 0.222z_{Danceability} + 0.556z_{Energy} - 0.115z_{Instrumantalness} + 0.476z_{Loudness} + 0.116z_{speechiness} + 0.107z_{tempo} + 0.403z_{valence} 
\\
\hat y_2 = -0.283z_{Popularity} - 0.102z_{Duration} -0.005z_{Acousticness} + 0.633z_{Danceability} - 0.146z_{Energy} + 0.120z_{Instrumantalness} - 0.253z_{Loudness} -0.264z_{speechiness} -0.448z_{tempo} + 0.371z_{valence}
\\
\hat y_3 = 0.654z_{Popularity} - 0.480z_{Duration} + 0.233z_{Acousticness} + 0.161z_{Danceability} - 0.164z_{Energy} - 0.342z_{Instrumantalness} + 0.131z_{Loudness} + 0.109z_{speechiness} - 0.295_{tempo} - 0.049z_{valence}
\\
\hat y_4 = -0.017z_{Popularity} - 0.549z_{Duration} - 0.009z_{Acousticness} - 0.046z_{Danceability} - 0.059z_{Energy} + 0.543z_{Instrumantalness} - 0.257z_{Loudness} + 0.469z_{speechiness} + 0.3172z_{tempo} + 0.100z_{valence}
\\
\hat y_5 = 0.307z_{Popularity} - 0.173z_{Duration} - 0.147z_{Acousticness} - 0.096z_{Danceability} + 0.094z_{Energy} + 0.572z_{Instrumantalness} + 0.193z_{Loudness} - 0.658z_{speechiness} - 0.047z_{tempo} - 0.192z_{valence} 
$$


INTERPRETATION OF THE PCs:     

* PC1: The variables with positive direction coefficients are: Energy, Loudness, Valence, Danceability, Speechiness, Tempo, and Popularity. Energy, Loudness and Valence having the greatest weights, therefore accounting for the majority of the variation in the positive direction. The negative weighted variables are Acousticness, Duration and Instrumentalness where Acousticness has the highest weight. The variables with the positive direction weights are ones that an average person would assume to be associated with fun, upbeat, pop hits as opposed to the variables that are weighted in the negative direction. A fun observation to point out is the contrast to the songs with mode = 1. Notice how there are similar groupings of variables, but with the signs flipped. This shows that songs that are in a minor key (mode = 0) experience opposite direction for similar groupings as major and minor key songs tend to give off opposite moods/tones from one another musically. 

* PC2: Variables weighted in the positive direction are: Danceability, Valence, Instrumentallness. Danceability being weighted the most heavily with a loading factor of 0.633. The variables weighted in the negative direction are: Tempo, Popularity, Loudness, Speechiness, Energy, Duraiton and Acousticness with Tempo holding the greatest negative weight at -0.448.

* PC3: For this PC, Popularity is weighted very heavily in the positive direction with a loading factor of 0.654 compared to other positively weighted variables such as Acousticness, Danceability, Loudness, and Speechiness. In the negative direction there is Duration, Instrumentalness, Tempo, Energy and Valence, where all variables except valence are weighted fairly equally in the negative direction, except Valence which is weighted much smaller than the rest. 

* PC4: In the negative direction, Duration is weighted the most at -0.549, followed by Loudness, at -0.257 and Energy with a loading factor of just -0.059 and. In the positive direction, Instrumentalness carreis the most weight with a loading factor of 0.543, followed by speechiness with a weight of 0.469, thne Tempo,  and Valence.

* PC5: The variables with weights in the positive direction are the variables Instrumentalness, Popularity, Loudness, and Energy where instrumentalness has the greatest weight due to its loading factor 0.572. The variables weighted in the negative direction are Speechiness, Valence, Duration, Acousticness, Danceability, and Tempo. Speechiness is the most heavily weighted with a loading factor of -0.658.



biplot
```{r}
biplot(pca0, scale = 0, xlabs=rep("Â·", nrow(mode0)))
```


examine amount of variance explained to choose optimal principal components
```{r}
pca0.var = pca0$sdev^2
pve0 = pca0.var/sum(pca0.var)
cve0 = cumsum(pve0)
pca0.var.explained <- data.frame("Variance" = pca0.var, 
                                "Proportion_Variation" = pve0, 
                                "Cummalitve_Proportion_Variation"= cve0, 
                                "PC" = factor(c("PC1", "PC2", "PC3", "PC4", "PC5", "PC6", "PC7",
                                         "PC8", "PC9", "PC10"), 
                                         levels = c("PC1", "PC2", "PC3", "PC4", "PC5", "PC6", "PC7",
                                         "PC8", "PC9", "PC10")))
pca0.var.explained
```



```{r}
pca0.var.explained %>%
  ggplot(aes(x=PC,y=Proportion_Variation, group=1))+
  ylab("Proportion of Variance Explained") +
  geom_point(size=3)+
  geom_line()+
  labs(title="Scree plot: PCA on scaled data") +
  theme_minimal()
```




## Clustering on PCA: Kmeans clustering ##
 
### for songs where mode = 0
Choosing number of groups (K) via elbow method
```{r}
pc0_1to5 <- data.frame(pca0$x[,1:5])
set.seed(123)
#compute total within cluster sum of square
wss <- function(k) {
  kmeans(pc0_1to5, k, iter.max = 1000, nstart = 25, algorithm = "Hartigan-Wong")$tot.withinss
}
k.vals <- 1:15
wss_values <- map_dbl(k.vals, wss)

plot(k.vals, wss_values,
       type="b", pch = 19, frame = FALSE, 
       xlab="Number of clusters K",
       ylab="Total within-clusters sum of squares")
```

silhouette method
```{r}
library(factoextra)
fviz_nbclust(pc0_1to5, kmeans, method="silhouette")
```


visualize the two clusters
```{r}
set.seed(123)
k <- kmeans(pc0_1to5, 2, iter.max = 1000, nstart = 25, algorithm = "Hartigan-Wong")
pc0_1to5$clusters <- as.factor(k$cluster)
ggplot(pc0_1to5, aes(PC1, PC2, color = clusters)) + geom_point() + 
  labs(title = "K-means Cluster on Principal Components", x = "PC1", y = "PC2") +
  theme_bw()
```

### for songs where mode = 1
Choosing number of groups (K) via elbow method
```{r}
pc1_1to5 <- data.frame(pca1$x[,1:5])
set.seed(123)
#compute total within cluster sum of square
wss <- function(k) {
  kmeans(pc1_1to5, k, iter.max = 1000, nstart = 25, algorithm = "Hartigan-Wong")$tot.withinss
}
k.vals <- 1:15
wss_values <- map_dbl(k.vals, wss)

plot(k.vals, wss_values,
       type="b", pch = 19, frame = FALSE, 
       xlab="Number of clusters K",
       ylab="Total within-clusters sum of squares")
```

silhouette method
```{r}
fviz_nbclust(pc1_1to5, kmeans, method="silhouette")
```

```{r}
set.seed(123)
k <- kmeans(pc1_1to5, 2, iter.max = 1000, nstart = 25, algorithm = "Hartigan-Wong")
pc1_1to5$clusters <- as.factor(k$cluster)
ggplot(pc1_1to5, aes(PC1, PC2, color = clusters)) + geom_point() + 
  labs(title = "K-means Cluster on Principal Components", x = "PC1", y = "PC2") +
  theme_bw()
```

## Heirarchical Clustering: Ward's method ##

```{r}
mode0.st <- scale(mode0)
mode1.st <- scale(mode1)

```


column means and covariates of songs with mode == 0
```{r}
colMeans(mode0.st);cov(mode0.st)
```


column means and covariates of songs with mode == 1
```{r}
colMeans(mode1.st);cov(mode1.st)
```



No issues of multicollinearity in either subset.

### Ward's Method: Mode 0

```{r}
mode0.d <- dist(mode0.st, method = "euclidean")
mode0_ward <- hclust(mode0.d, method = "ward.D2")
plot(mode0_ward)
```

The largest distance from the first cluster can be observed on the left side where the height has a distance of about 30. Therefore, Ward's method groups the dataset into 3 clusters. 

```{r}
plot(mode0_ward)
rect.hclust(mode0_ward, k=3, border="red")
```


We can see that there is one large cluster to the left, a very small amount of songs in the second cluster and about 1/5 of the songs in the 3rd cluster. Lets see exactly how many songs are assigned to each cluster:
```{r}
mode0.groups <- cutree(mode0_ward, k=3)
table(mode0.groups)
table(mode0.groups)/nrow(mode0)
```



### Ward's Method: Mode 1

```{r}
mode1.d <- dist(mode1.st, method = "euclidean")
mode1_ward <- hclust(mode1.d, method = "ward.D2")
plot(mode1_ward)
```

Similarly to the songs where mode = 0, Ward's heirarchical method clusters the music into 3 separate groups. In addition, the 2nd group is also extremely small compared to the rest of the music.


```{r}
plot(mode1_ward)
rect.hclust(mode1_ward, k=3, border="red")
```


```{r}
mode1.groups <- cutree(mode1_ward, k=3)
table(mode1.groups)
table(mode1.groups)/nrow(mode1)
```



